# Projeto 4 ‚Äì Chatbot Jur√≠dico com RAG e AWS Bedrock  
**Sprint 7 e 8 ‚Äì Scholarship Compass UOL ‚Äì Forma√ß√£o em Intelig√™ncia Artificial para AWS**

## üìå Vis√£o Geral
Este projeto consiste na implementa√ß√£o de um **chatbot jur√≠dico** utilizando a arquitetura **RAG (Retrieval-Augmented Generation)**.  
O sistema realiza consultas em uma base de documentos jur√≠dicos armazenada no **Amazon S3**, gera embeddings com **Amazon Bedrock**, indexa com **ChromaDB** e exp√µe a interface de intera√ß√£o via **Telegram**.  

Toda a orquestra√ß√£o do fluxo √© feita a partir de uma **inst√¢ncia EC2**, sendo acionada por um **Lambda** que recebe gatilhos do **API Gateway**, com monitoramento de logs via **Amazon CloudWatch**.  

---

## üèóÔ∏è Arquitetura
Fluxo principal:
1. Usu√°rios enviam mensagens ao chatbot pelo **Telegram**.  
2. O **API Gateway** recebe a requisi√ß√£o.  
3. O **Lambda** √© acionado e redireciona a requisi√ß√£o para a aplica√ß√£o rodando em uma **inst√¢ncia EC2**.  
4. A aplica√ß√£o na **EC2** rodando em docker, utilizando **LangChain**, realiza:  
   - Leitura de documentos jur√≠dicos armazenados no **S3 (dataset jur√≠dico)**;  
   - Cria√ß√£o de embeddings utilizando **Amazon Bedrock**;  
   - Indexa√ß√£o dos embeddings no **ChromaDB** para recupera√ß√£o eficiente;  
   - Execu√ß√£o do mecanismo de **RAG** (busca + gera√ß√£o de resposta).  
5. A resposta √© enviada de volta ao usu√°rio via **Telegram**.  
6. Logs e eventos s√£o registrados no **Amazon CloudWatch**.  

---

## ‚öôÔ∏è Tecnologias Utilizadas
- **AWS**
  - Amazon S3 ‚Üí armazenamento dos documentos jur√≠dicos  
  - Amazon Bedrock ‚Üí gera√ß√£o de embeddings e consultas  
  - Amazon EC2 ‚Üí execu√ß√£o da aplica√ß√£o  
  - Amazon API Gateway ‚Üí exposi√ß√£o da API para o Telegram  
  - AWS Lambda ‚Üí intermedia√ß√£o entre API Gateway e EC2  
  - Amazon CloudWatch ‚Üí monitoramento e logging  

- **Frameworks/Bibliotecas**
  - Python 3.x  
  - [LangChain](https://python.langchain.com/) ‚Üí orquestra√ß√£o do RAG  
  - [LangChain AWS](https://pypi.org/project/langchain-aws/) ‚Üí integra√ß√£o com Bedrock  
  - [LangChain Community](https://pypi.org/project/langchain-community/) ‚Üí loaders e utilidades  
  - [ChromaDB](https://www.trychroma.com/) ‚Üí armazenamento vetorial  
  - [unstructured](https://unstructured-io.github.io/unstructured/) ‚Üí processamento de PDFs  
  - PyPDFLoader (LangChain) ‚Üí carregamento de documentos PDF  
  - [FastAPI](https://fastapi.tiangolo.com/) ‚Üí cria√ß√£o da API  
  - [Uvicorn](https://www.uvicorn.org/) ‚Üí servidor ASGI  
  - [python-telegram-bot](https://github.com/python-telegram-bot/python-telegram-bot) ‚Üí integra√ß√£o com Telegram  
  - [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) ‚Üí SDK AWS  

---

## üìÇ Estrutura de Pastas
```bash
üì¶ projeto-chatbot
 ‚î£ üìÇ src/
 ‚îÉ ‚î£ üìÇ indexing/    # carregamento de dados, gera√ß√£o de embeddings e armazenamento (ChromaDB)
 ‚îÉ ‚î£ üìÇ llm/         # acesso ao LLM
 ‚îÉ ‚î£ üìÇ rag/         # consultas e RAG com LangChain
 ‚îÉ ‚î£ main.py
 ‚î£ Dockerfile
 ‚î£ README.md
 ‚î£ testes.txt
 ‚îó requirements.txt

 ## Testes BDD (exemplos)

```gherkin
Feature: Gera√ß√£o de respostas com IA generativa via AWS Bedrock

  Scenario: Usu√°rio faz uma pergunta simples e recebe resposta
    Given que o sistema est√° em execu√ß√£o
    When o usu√°rio envia a pergunta "Qual a capital da Fran√ßa?"
    Then o sistema deve retornar uma resposta contendo "Paris"

  Scenario: Usu√°rio faz uma pergunta baseada em documentos indexados
    Given que documentos foram carregados e indexados no vetor store
    When o usu√°rio pergunta "Qual o valor da d√≠vida discutida no processo?"
    Then a resposta deve usar informa√ß√µes recuperadas dos documentos

  Scenario: Indexa√ß√£o de novo documento
    Given que um novo documento "manual.pdf" foi carregado
    When o sistema processar a indexa√ß√£o
    Then o documento deve estar acess√≠vel para futuras consultas

  Scenario: Consulta com contexto n√£o encontrado
    Given que nenhum documento cont√©m informa√ß√µes sobre "foguetes espaciais"
    When o usu√°rio pergunta "Qual o combust√≠vel do foguete?"
    Then o sistema deve retornar uma resposta gen√©rica indicando n√£o ter conhecimento sobre o assunto
